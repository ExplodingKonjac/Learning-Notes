\section{线性变换 IV}

\subsection{对角矩阵}

\begin{theorem}
	设 $\mathscr{A} \in \operatorname{End}(V)$，那么 $\mathscr{A}$ 的矩阵可以在某组基下为对角矩阵的充要条件是 $\mathscr{A}$ 有 $n$ 个线性无关的特征向量。

	\begin{proof}
		\begin{itemize}
			\item 充分性：取特征向量为一组基即可；
			\item 必要性：若 $\mathscr{A}$ 在 $\vect{\varepsilon}_1, \vect{\varepsilon}_2, \dots, \vect{\varepsilon}_n$ 下的矩阵为对角矩阵 $\diag(\lambda_1, \lambda_2, \dots, \lambda_n)$，那么 $\mathscr{A}(\vect{\varepsilon}_i) = \lambda_i \vect{\varepsilon}_i$，所以 $\mathscr{A}$ 有 $n$ 个线性无关的特征向量。
		\end{itemize}
	\end{proof}
\end{theorem}

\begin{theorem}
	属于不同特征值的特征向量线性无关。

	\begin{proof}
		要证：若 $\vect{\xi}_1, \vect{\xi}_2, \dots, \vect{\xi}_n$ 是 $\lambda_1, \lambda_2, \dots, \lambda_n$ 的特征向量，且 $\lambda_1, \lambda_2, \dots, \lambda_n$ 互不相同，那么 $\vect{\xi}_1, \vect{\xi}_2, \dots, \vect{\xi}_n$ 线性无关。

		使用数学归纳。$k=1$ 时显然成立，现在假设 $k - 1$ 时成立：

		若存在 $a_1, a_2, \dots, a_k \in P$ 满足 $\sum_{i=1}^n a_i \vect{\xi_i} = \vect{0}$，那么：
		$$
		\sum_{i=1}^k a_i \lambda_i \vect{\xi}_i = \sum_{i=1}^k a_i \mathscr{A}(\vect{\xi}_i) = \mathscr{A}\ab(\sum_{i=1}^k a_i \vect{\xi}_i) = \mathscr{A}(\vect{0}) = \vect{0}
		$$
		那么：
		$$
		\sum_{i=1}^k a_i \lambda_i \vect{\xi}_i - \lambda_k \sum_{i=1}^k a_i \vect{\xi}_i = \sum_{i=1}^{k-1} a_i (\lambda_i - \lambda_k) \vect{\xi}_i = \vect{0}
		$$
		而根据归纳假设 $\vect{\xi}_1, \vect{\xi}_2, \dots, \vect{\xi}_{k-1}$ 线性无关，因此 $a_i (\lambda_i - \lambda_k) = 0$，因此 $a_1 = a_2 = \dots = a_{k-1} = 0$，进一步推出 $a_k = 0$。因此 $\vect{\xi}_1, \vect{\xi}_2, \dots, \vect{\xi}_n$ 线性无关。
	\end{proof}
\end{theorem}

\begin{corollary}
	若 $\mathscr{A} \in \operatorname{End}(\mathbb{R})$ 的特征多项式没有重根，那么 $\mathscr{A}$ 在某组基下的矩阵是对角矩阵。
\end{corollary}

\begin{corollary}
	$\mathscr{A}$ 的每个特征值的特征子空间 $V_1, V_2, \dots, V_k$ 的和是直和。
\end{corollary}

基于这个推论，我们可以对于每个特征值 $\lambda_i$，通过求解 $(\lambda_i \matr{E} - \matr{A}) \vect{x} = \vect{0}$ 来求解出 $\lambda_i$ 的特征子空间，然后把这些特征子空间的基放到一起就得到了 $\matr{A}$ 的所有线性无关的特征向量。

假设找到了 $n$ 个特征向量 $\vect{\xi}_1, \vect{\xi}_2, \dots, \vect{\xi}_n$，其对应的特征值为 $\lambda_1, \lambda_2, \dots, \lambda_n$，那么我们记
$$
\matr{M} = \begin{bmatrix}
	\vect{\xi}_1 & \vect{\xi}_2 & \cdots & \vect{\xi}_n
\end{bmatrix}
$$
可以得到：
$$
\matr{A} \matr{M} = \matr{M} \diag(\lambda_1, \lambda_2, \dots, \lambda_n)
$$
因此
$$
\matr{M}^{-1} \matr{A} \matr{M} = \diag(\lambda_1, \lambda_2, \dots, \lambda_n)
$$
至此就完成了 $\matr{A}$ 的相似对角化。

\subsection{值域与核}

\begin{definition}[线性变换的值域与核]
	对于 $\mathscr{A} \in \operatorname{End}(V)$，我们称 $\{\mathscr{A}(\vect{v}): \vect{v} \in V\}$ 为 $\mathscr{A}$ 的\textbf{值域}，记作
	$$
	\mathscr{A}(V) \text{ 或 } \image \mathscr{A}
	$$
	同时，我们称 $\{\vect{v}: \mathscr{A}(\vect{v}) = \vect{0}\}$ 为 $\mathscr{A}$ 的\textbf{核}，记作
	$$
	\mathscr{A}^{-1}(\vect{0}) \text{ 或 } \ker \mathscr{A}
	$$
	同时，我们称 $\dim \mathscr{A}(V)$ 为 $\mathscr{A}$ 的\textbf{秩}，称 $\dim \ker \mathscr{A}$ 为 $\mathscr{A}$ 的\textbf{零度}。
\end{definition}

显然 $\image \mathscr{A}, \ker \mathscr{A}$ 都是 $V$ 的子空间。

\begin{theorem}[秩-零度定理]
	$$
	\rank \mathscr{A} + \dim \ker \mathscr{A} = \dim V
	$$
\end{theorem}

\section{作业}

\begin{problem}
	第七章习题 16

	\begin{proof}
		记交换第 $i$ 行、第 $j$ 行对应的初等矩阵为 $\matr{X}_{i,j}$，那么可知对于对角阵 $\matr{A}$：
		$$
		\matr{X}_{i,j} \matr{A} \matr{X}_{i,j}^{-1}
		$$
		是交换 $\matr{A}$ 的 $(i, i), (j, j)$ 元素得到的矩阵。而
		$$
		\diag(\lambda_1, \lambda_2, \dots, \lambda_n),\ \diag(\lambda_{i_1}, \lambda_{i_2}, \dots, \lambda_{i_n})
		$$
		之间显然可以通过有限次交换 $(i, i), (j, j)$ 操作得到，因此两个矩阵相似。
	\end{proof}
\end{problem}

\begin{problem}
	第七章习题 17
	\begin{proof}
		$$
		\matr{A}^{-1} (\matr{A} \matr{B}) \matr{A} = \matr{B} \matr{A}
		$$
	\end{proof}
\end{problem}

\begin{problem}
	第七章习题 19

	\begin{solution}
		\begin{enumerate}
			\item[\textbf{2)}]
			$$
			\det(\lambda \matr{E} - \matr{A}) = \begin{vmatrix}
				\lambda & -a \\
				a & \lambda
			\end{vmatrix} = \lambda^2 + a^2 = 0
			$$
			解得两个特征值 $\lambda_1 = a \I,\ \lambda_2 = -a \I$。
			
			\begin{itemize}
				\item 对于 $\lambda_1 = a \I$：
				$$
				(\lambda_1 \matr{E} - \matr{A}) \vect{x}_1 = \begin{bmatrix}
					a \I & -a \\
					a & a \I
				\end{bmatrix} \vect{x}_1 = \vect{0}
				$$
				解得 $\vect{x}_1 = \alpha \transpose{[\I, -1]}$。

				\item 对于 $\lambda_2 = -a \I$：
				$$
				(\lambda_2 \matr{E} - \matr{A}) \vect{x}_2 = \begin{bmatrix}
					-a \I & -a \\
					a & -a \I
				\end{bmatrix} \vect{x}_2 = \vect{0}
				$$
				解得 $\vect{x}_2 = \beta \transpose{[\I, 1]}$。
			\end{itemize}

			\item[\textbf{3)}]
			$$
			\begin{aligned}
				\det(\lambda \matr{E} - \matr{A}) & = \begin{vmatrix}
					\lambda - 1 & -1 & -1 & -1 \\
					-1 & \lambda - 1 & 1 & 1 \\
					-1 & 1 & \lambda - 1 & 1 \\
					-1 & 1 & 1 & \lambda - 1
				\end{vmatrix} \\
				& = \begin{vmatrix}
					\lambda & 0 & 0 & 0 \\
					-1 & \lambda - 1 & 1 & 1 \\
					-1 & 1 & \lambda - 1 & 1 \\
					-1 & 1 & 1 & \lambda - 1
				\end{vmatrix} + \begin{vmatrix}
					-1 & -1 & -1 & -1 \\
					-1 & \lambda - 1 & 1 & 1 \\
					-1 & 1 & \lambda - 1 & 1 \\
					-1 & 1 & 1 & \lambda - 1
				\end{vmatrix} \\
				& = \lambda \begin{vmatrix}
					\lambda - 1 & 1 & 1 \\
					1 & \lambda - 1 & 1 \\
					1 & 1 & \lambda - 1
				\end{vmatrix} - \begin{vmatrix}
					\lambda & 2 & 2 \\
					2 & \lambda & 2 \\
					2 & 2 & \lambda
				\end{vmatrix} \\
				& = (\lambda - 2)^3 (\lambda + 2) = 0
			\end{aligned}
			$$
			解得 $\lambda_1 = 2,\ \lambda_2 = -2$。

			\begin{itemize}
				\item 对于 $\lambda_1 = 2$：
				$$
				(\lambda_1 \matr{E} - \matr{A}) \vect{x}_1 = \begin{bmatrix}
					1 & -1 & -1 & -1 \\
					-1 & 1 & 1 & 1 \\
					-1 & 1 & 1 & 1 \\
					-1 & 1 & 1 & 1
				\end{bmatrix} \vect{x}_1 = \vect{0}
				$$
				解得 $\vect{x}_1 = \alpha_1 \transpose{[1, -1, 0, 0]} + \alpha_2 \transpose{[1, 0, -1, 0]} + \alpha_3 \transpose{[1, 0, 0, -1]}$。

				\item 对于 $\lambda_2 = -2$：
				$$
				(\lambda_2 \matr{E} - \matr{A}) \vect{x}_2 = \begin{bmatrix}
					-3 & -1 & -1 & -1 \\
					-1 & -3 & 1 & 1 \\
					-1 & 1 & -3 & 1 \\
					-1 & 1 & 1 & -3
				\end{bmatrix} \vect{x}_2 = \vect{0}
				$$
				解得 $\vect{x}_2 = \beta \transpose{[-1, 1, 1, 1]}$。
			\end{itemize}

			\item[\textbf{5)}]
			$$
			\det(\lambda \matr{E} - \matr{A}) = \begin{vmatrix}
				\lambda & 0 & -1 \\
				0 & \lambda - 1 & 0 \\
				-1 & 0 & \lambda
			\end{vmatrix} = (\lambda + 1)(\lambda - 1)^2 = 0
			$$
			解得 $\lambda_1 = 1, \lambda_2 = -1$。

			\begin{itemize}
				\item 对于 $\lambda_1 = 1$：
				$$
				(\lambda_1 \matr{E} - \matr{A}) \vect{x}_1 = \begin{bmatrix}
					1 & 0 & -1 \\
					0 & 0 & 0 \\
					-1 & 0 & 1
				\end{bmatrix} \vect{x}_1 = \vect{0}
				$$
				解得 $\vect{x}_1 = \alpha_1 \transpose{[1, 0, 1]} + \alpha_2 \transpose{[0, 1, 0]}$。

				\item 对于 $\lambda_2 = -1$：
				$$
				(\lambda_2 \matr{E} - \matr{A}) \vect{x}_2 = \begin{bmatrix}
					-1 & 0 & -1 \\
					0 & -2 & 0 \\
					-1 & 0 & -1
				\end{bmatrix} \vect{x}_2 = \vect{0}
				$$
				解得 $\vect{x}_2 = \beta \transpose{[1, 0, -1]}$。
			\end{itemize}
		\end{enumerate}
	\end{solution}
\end{problem}

\begin{problem}
	第七章习题 20

	\begin{solution}
		\begin{enumerate}
			\item[\textbf{3)}] 由题知，在基
			$$
			\vect{\varepsilon}_1 = \cvec{1, -1, 0, 0}, \vect{\varepsilon}_2 = \cvec{1, 0, -1, 0}, \vect{\varepsilon}_3 = \cvec{1, 0, 0, -1}, \vect{\varepsilon}_4 = \cvec{-1, 1, 1, 1}
			$$
			下，$\mathscr{A}$ 的矩阵为对角矩阵。因此存在
			$$
			\matr{T} = \begin{bmatrix}
				1 & 1 & 1 & -1 \\
				-1 & 0 & 0 & 1 \\
				0 & -1 & 0 & 1 \\
				0 & 0 & -1 & 1
			\end{bmatrix}
			$$
			使得
			$$
			\matr{T}^{-1} \matr{A} \matr{T} = \diag(2, 2, 2, -2)
			$$

			\item[\textbf{5)}] 由题知，在基
			$$
			\vect{\varepsilon}_1 = \cvec{1, 0, 1}, \vect{\varepsilon}_2 = \cvec{0, 1, 0}, \vect{\varepsilon}_3 = \cvec{1, 0, -1}
			$$
			下，$\mathscr{A}$ 的矩阵为对角矩阵。因此存在
			$$
			\matr{T} = \begin{bmatrix}
				1 & 0 & 1 \\
				0 & 1 & 0 \\
				1 & 0 & -1
			\end{bmatrix}
			$$
			使得
			$$
			\matr{T}^{-1} \matr{A} \matr{T} = \diag(1, 1, -1)
			$$
		\end{enumerate}
	\end{solution}
\end{problem}

\begin{problem}
	第七章习题 24

	\begin{proof}
		\begin{enumerate}
			\item[\textbf{1)}]
			$$
			\mathscr{A}(\vect{\varepsilon}_1 + \vect{\varepsilon}_2) = \mathscr{A}(\vect{\varepsilon}_1) + \mathscr{A}(\vect{\varepsilon}_2) = \lambda_1 \vect{\varepsilon}_1 + \lambda_2 \vect{\varepsilon}_2
			$$
			若 $\vect{\varepsilon}_1 + \vect{\varepsilon}_2$ 也是 $\mathscr{A}$ 的特征向量，那么存在 $\lambda$：
			$$
			\lambda_1 \vect{\varepsilon}_1 + \lambda_2 \vect{\varepsilon}_2 = \lambda (\vect{\varepsilon}_1 + \vect{\varepsilon}_2)
			$$
			即
			$$
			(\lambda_1 - \lambda) \vect{\varepsilon}_1 + (\lambda_2 - \lambda) \vect{\varepsilon}_2 = \vect{0}
			$$
			因为 $\vect{\varepsilon}_1, \vect{\varepsilon}_2$ 线性无关，所以 $\lambda_1 - \lambda = \lambda_2 - \lambda = 0$，这与 $\lambda_1 \neq \lambda_2$ 矛盾。故得证。
		\end{enumerate}
	\end{proof}
\end{problem}